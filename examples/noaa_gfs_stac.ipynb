{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a STAC Item for the NOAA GFS Forecast (dynamical.org Icechunk)\n",
    "\n",
    "This notebook shows how to use `cloudify.stac` to generate a STAC item for the\n",
    "[NOAA GFS Forecast](https://dynamical.org/catalog/noaa-gfs-forecast/) dataset\n",
    "published by [dynamical.org](https://dynamical.org) as a public Icechunk store on AWS S3.\n",
    "\n",
    "The dataset is a **regular** (non-virtual) Icechunk store — chunk data lives\n",
    "directly in the repo, not in referenced external files.\n",
    "\n",
    "## Install dependencies\n",
    "```\n",
    "pip install icechunk xarray zarr pystac xstac cloudify\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import icechunk\n",
    "import pystac\n",
    "import xarray as xr\n",
    "\n",
    "from cloudify.stac import build_stac_item_from_icechunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Open the Icechunk store\n",
    "\n",
    "We open the `main` branch and capture the current snapshot ID.\n",
    "The snapshot ID pins the STAC item to a specific, reproducible version of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = \"dynamical-noaa-gfs\"\n",
    "PREFIX = \"noaa-gfs-forecast/v0.2.7.icechunk/\"\n",
    "REGION = \"us-west-2\"\n",
    "ICECHUNK_HREF = f\"s3://{BUCKET}/{PREFIX}\"\n",
    "\n",
    "storage = icechunk.s3_storage(\n",
    "    bucket=BUCKET,\n",
    "    prefix=PREFIX,\n",
    "    region=REGION,\n",
    "    anonymous=True,\n",
    ")\n",
    "repo = icechunk.Repository.open(storage)\n",
    "session = repo.readonly_session(\"main\")\n",
    "\n",
    "snapshot_id = session.snapshot_id\n",
    "print(f\"snapshot_id: {snapshot_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_zarr(session.store, chunks=None)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define storage schemes and providers\n",
    "\n",
    "`storage_schemes` describes the S3 backend so that tools like\n",
    "[xpystac](https://github.com/stac-utils/xpystac) can reconstruct the\n",
    "icechunk storage config from the STAC asset alone.\n",
    "\n",
    "**Important:** `storage_schemes` is stored at the top-level item\n",
    "`extra_fields` (not inside `properties`) — that is where `xpystac` looks\n",
    "for it when you call `xr.open_dataset(asset)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_schemes = {\n",
    "    \"aws-s3-dynamical-noaa-gfs\": {\n",
    "        \"type\": \"aws-s3\",\n",
    "        \"platform\": \"https://{bucket}.s3.{region}.amazonaws.com\",\n",
    "        \"bucket\": BUCKET,\n",
    "        \"region\": REGION,\n",
    "        \"anonymous\": True,\n",
    "    }\n",
    "}\n",
    "\n",
    "providers = [\n",
    "    pystac.Provider(\n",
    "        name=\"dynamical.org\",\n",
    "        description=\"Analysis-ready, cloud-optimized weather forecast data\",\n",
    "        roles=[\"producer\", \"processor\", \"host\"],\n",
    "        url=\"https://dynamical.org\",\n",
    "    ),\n",
    "    pystac.Provider(\n",
    "        name=\"NOAA NCEP\",\n",
    "        description=\"National Oceanic and Atmospheric Administration — Global Forecast System\",\n",
    "        roles=[\"producer\", \"licensor\"],\n",
    "        url=\"https://www.ncep.noaa.gov\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build the STAC item\n",
    "\n",
    "Two GFS-specific arguments differ from the defaults:\n",
    "\n",
    "- `temporal_dimension=\"init_time\"` — GFS uses `init_time` (forecast\n",
    "  initialisation time) rather than the generic `time`\n",
    "- `x_dimension=\"longitude\"`, `y_dimension=\"latitude\"` — full names, not\n",
    "  the abbreviated `lon`/`lat`\n",
    "- `virtual=False` — this is a regular Icechunk store, not a virtual one\n",
    "  (chunk data lives in the repo, not in referenced external files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_id = f\"noaa-gfs-forecast-{snapshot_id.lower()}\"\n",
    "\n",
    "item = build_stac_item_from_icechunk(\n",
    "    ds,\n",
    "    item_id=item_id,\n",
    "    icechunk_href=ICECHUNK_HREF,\n",
    "    snapshot_id=snapshot_id,\n",
    "    storage_schemes=storage_schemes,\n",
    "    title=\"NOAA GFS Forecast (dynamical.org)\",\n",
    "    description=ds.attrs.get(\"description\", \n",
    "        \"NOAA Global Forecast System (GFS) weather forecast data, \"\n",
    "        \"analysis-ready and cloud-optimized by dynamical.org. \"\n",
    "        \"Global coverage at 0.25° resolution, initialized every 6 hours, \"\n",
    "        \"with forecast lead times from 0 to 384 hours.\"\n",
    "    ),\n",
    "    providers=providers,\n",
    "    virtual=False,                   # regular icechunk, not virtual\n",
    "    temporal_dimension=\"init_time\",  # GFS-specific\n",
    "    x_dimension=\"longitude\",\n",
    "    y_dimension=\"latitude\",\n",
    ")\n",
    "\n",
    "print(json.dumps(item, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Inspect key fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"bbox:           \", item[\"bbox\"])\nprint(\"start_datetime: \", item[\"properties\"][\"start_datetime\"])\nprint(\"end_datetime:   \", item[\"properties\"][\"end_datetime\"])\nprint(\"variables:      \", list(item[\"properties\"][\"cube:variables\"].keys()))\nprint()\nprint(\"assets:\")\nfor key, asset in item[\"assets\"].items():\n    print(f\"  {key}: {asset['href']}\")\n    print(f\"    snapshot_id:  {asset.get('icechunk:snapshot_id')}\")\n    print(f\"    roles:        {asset['roles']}\")\nprint()\nprint(\"storage:schemes at top level:\", \"storage:schemes\" in item)\nprint(\"storage:schemes in properties (should be False):\",\n      \"storage:schemes\" in item.get(\"properties\", {}))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save and round-trip via xpystac\n",
    "\n",
    "Save the item to disk, reload it with pystac, and open the data directly\n",
    "from the asset using `xr.open_dataset(asset)` — this exercises the full\n",
    "round-trip that end users of the STAC catalog will follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = f\"{item_id}.json\"\n",
    "with open(out_path, \"w\") as f:\n",
    "    json.dump(item, f, indent=2)\n",
    "print(f\"Written to {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload and open via xpystac  (requires: pip install xpystac)\n",
    "loaded_item = pystac.Item.from_file(out_path)\n",
    "\n",
    "# The asset key is \"{name}@{snapshot_id}\"\n",
    "asset_key = next(k for k in loaded_item.assets if \"@\" in k)\n",
    "asset = loaded_item.assets[asset_key]\n",
    "print(f\"Opening asset: {asset_key}\")\n",
    "\n",
    "# xpystac detects the icechunk media type and reconstructs the repo\n",
    "# from storage:schemes + icechunk:snapshot_id automatically\n",
    "ds_from_stac = xr.open_dataset(asset)\n",
    "ds_from_stac"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}