{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Static STAC Catalog and Browse with STAC Browser\n",
    "\n",
    "This notebook builds STAC items for three public icechunk stores, assembles\n",
    "them into a static STAC catalog, saves it to an S3 bucket, and produces a\n",
    "[STAC Browser](https://github.com/radiantearth/stac-browser) URL for\n",
    "immediate browsing — no server required.\n",
    "\n",
    "## Architecture\n",
    "\n",
    "```\n",
    "s3://BUCKET/PREFIX/\n",
    "  catalog.json\n",
    "  noaa-gfs-forecast-{snapshot}.json\n",
    "  noaa-hrrr-forecast-48-hour-{snapshot}.json\n",
    "  nldas-3-virtual-zarr-{snapshot}.json\n",
    "```\n",
    "\n",
    "The catalog is served as public static JSON. STAC Browser is a client-side\n",
    "Vue.js app hosted by Radiant Earth — it fetches and renders the catalog\n",
    "directly from S3 with no backend.\n",
    "\n",
    "## Install dependencies\n",
    "```\n",
    "pip install icechunk xarray zarr pystac xstac rioxarray s3fs cloudify\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import warnings\n",
    "from abc import ABC\n",
    "from pathlib import Path\n",
    "\n",
    "import fsspec\n",
    "import icechunk\n",
    "import pystac\n",
    "import rioxarray\n",
    "import xarray as xr\n",
    "\n",
    "from cloudify.stac import build_stac_item_from_icechunk\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"Numcodecs codecs are not in the Zarr version 3 specification*\",\n",
    "    category=UserWarning,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configure the output catalog location\n",
    "\n",
    "Set `CATALOG_BUCKET` and `CATALOG_PREFIX` to a publicly-readable S3 location\n",
    "you have write access to.  The bucket must allow public `s3:GetObject` so\n",
    "STAC Browser can fetch the JSON files from the browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATALOG_BUCKET = \"my-public-bucket\"      # ← change me\n",
    "CATALOG_PREFIX = \"stac/weather-forecasts\" # ← change me\n",
    "\n",
    "CATALOG_ROOT = f\"s3://{CATALOG_BUCKET}/{CATALOG_PREFIX}\"\n",
    "CATALOG_ROOT_HTTPS = f\"https://{CATALOG_BUCKET}.s3.amazonaws.com/{CATALOG_PREFIX}\"\n",
    "print(f\"Catalog will be written to: {CATALOG_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Custom StacIO that writes to S3\n",
    "\n",
    "pystac's `save()` calls `StacIO.write_text_method()` for each file.\n",
    "We override it to write to S3 via fsspec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FsspecStacIO(pystac.StacIO):\n",
    "    \"\"\"StacIO that reads/writes via fsspec (supports s3://, local, etc.).\"\"\"\n",
    "\n",
    "    def read_text_method(self, source, *args, **kwargs):\n",
    "        with fsspec.open(str(source), \"r\") as f:\n",
    "            return f.read()\n",
    "\n",
    "    def write_text_method(self, dest, txt):\n",
    "        with fsspec.open(str(dest), \"w\") as f:\n",
    "            f.write(txt)\n",
    "        print(f\"  written: {dest}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build STAC items for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_icechunk(bucket, prefix, region, anonymous=True,\n",
    "                  virtual_source=None, snapshot_id=None, branch=\"main\"):\n",
    "    \"\"\"Open an icechunk repo and return (session, ds).\"\"\"\n",
    "    storage = icechunk.s3_storage(\n",
    "        bucket=bucket, prefix=prefix, region=region, anonymous=anonymous\n",
    "    )\n",
    "    config = icechunk.RepositoryConfig.default()\n",
    "    repo_kwargs = {\"storage\": storage, \"config\": config}\n",
    "\n",
    "    if virtual_source:\n",
    "        config.set_virtual_chunk_container(\n",
    "            icechunk.VirtualChunkContainer(\n",
    "                virtual_source, icechunk.s3_store(region=region)\n",
    "            )\n",
    "        )\n",
    "        repo_kwargs[\"authorize_virtual_chunk_access\"] = icechunk.containers_credentials(\n",
    "            {virtual_source: icechunk.s3_anonymous_credentials()}\n",
    "        )\n",
    "\n",
    "    repo = icechunk.Repository.open(**repo_kwargs)\n",
    "    session = repo.readonly_session(\n",
    "        snapshot_id=snapshot_id if snapshot_id else branch\n",
    "    ) if snapshot_id else repo.readonly_session(branch=branch)\n",
    "    ds = xr.open_zarr(session.store, chunks=None, consolidated=False, zarr_format=3)\n",
    "    return session, ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Opening GFS...\")\n",
    "gfs_session, gfs_ds = open_icechunk(\n",
    "    bucket=\"dynamical-noaa-gfs\",\n",
    "    prefix=\"noaa-gfs-forecast/v0.2.7.icechunk/\",\n",
    "    region=\"us-west-2\",\n",
    ")\n",
    "print(f\"  snapshot: {gfs_session.snapshot_id}  dims: {dict(gfs_ds.sizes)}\")\n",
    "\n",
    "print(\"Opening HRRR...\")\n",
    "hrrr_session, hrrr_ds = open_icechunk(\n",
    "    bucket=\"dynamical-noaa-hrrr\",\n",
    "    prefix=\"noaa-hrrr-forecast-48-hour/v0.1.0.icechunk/\",\n",
    "    region=\"us-west-2\",\n",
    ")\n",
    "print(f\"  snapshot: {hrrr_session.snapshot_id}  dims: {dict(hrrr_ds.sizes)}\")\n",
    "\n",
    "NLDAS_SNAPSHOT = \"YTNGFY4WY9189GEH1FNG\"\n",
    "NLDAS_VIRTUAL_SOURCE = \"s3://nasa-waterinsight/NLDAS3/forcing/daily/\"\n",
    "print(\"Opening NLDAS-3...\")\n",
    "nldas_session, nldas_ds = open_icechunk(\n",
    "    bucket=\"nasa-waterinsight\",\n",
    "    prefix=\"virtual-zarr-store/NLDAS-3-icechunk/\",\n",
    "    region=\"us-west-2\",\n",
    "    virtual_source=NLDAS_VIRTUAL_SOURCE,\n",
    "    snapshot_id=NLDAS_SNAPSHOT,\n",
    ")\n",
    "print(f\"  snapshot: {nldas_session.snapshot_id}  dims: {dict(nldas_ds.sizes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pystac\n",
    "\n",
    "gfs_snap = gfs_session.snapshot_id\n",
    "hrrr_snap = hrrr_session.snapshot_id\n",
    "\n",
    "gfs_item_dict = build_stac_item_from_icechunk(\n",
    "    gfs_ds,\n",
    "    item_id=f\"noaa-gfs-forecast-{gfs_snap.lower()}\",\n",
    "    icechunk_href=\"s3://dynamical-noaa-gfs/noaa-gfs-forecast/v0.2.7.icechunk/\",\n",
    "    snapshot_id=gfs_snap,\n",
    "    storage_schemes={\"aws-s3-dynamical-noaa-gfs\": {\n",
    "        \"type\": \"aws-s3\", \"bucket\": \"dynamical-noaa-gfs\",\n",
    "        \"region\": \"us-west-2\", \"anonymous\": True,\n",
    "    }},\n",
    "    title=\"NOAA GFS Forecast (dynamical.org)\",\n",
    "    providers=[pystac.Provider(name=\"dynamical.org\", roles=[\"producer\",\"processor\",\"host\"], url=\"https://dynamical.org\")],\n",
    "    virtual=False,\n",
    "    temporal_dimension=\"init_time\", x_dimension=\"longitude\", y_dimension=\"latitude\",\n",
    ")\n",
    "\n",
    "hrrr_crs = hrrr_ds.rio.crs\n",
    "hrrr_item_dict = build_stac_item_from_icechunk(\n",
    "    hrrr_ds,\n",
    "    item_id=f\"noaa-hrrr-forecast-48-hour-{hrrr_snap.lower()}\",\n",
    "    icechunk_href=\"s3://dynamical-noaa-hrrr/noaa-hrrr-forecast-48-hour/v0.1.0.icechunk/\",\n",
    "    snapshot_id=hrrr_snap,\n",
    "    storage_schemes={\"aws-s3-dynamical-noaa-hrrr\": {\n",
    "        \"type\": \"aws-s3\", \"bucket\": \"dynamical-noaa-hrrr\",\n",
    "        \"region\": \"us-west-2\", \"anonymous\": True,\n",
    "    }},\n",
    "    title=\"NOAA HRRR 48-Hour Forecast (dynamical.org)\",\n",
    "    providers=[pystac.Provider(name=\"dynamical.org\", roles=[\"producer\",\"processor\",\"host\"], url=\"https://dynamical.org\")],\n",
    "    virtual=False,\n",
    "    temporal_dimension=\"init_time\", x_dimension=\"x\", y_dimension=\"y\",\n",
    "    reference_system=hrrr_crs.to_epsg() or hrrr_crs.to_wkt(),\n",
    ")\n",
    "\n",
    "nldas_item_dict = build_stac_item_from_icechunk(\n",
    "    nldas_ds,\n",
    "    item_id=f\"nldas-3-virtual-zarr-{NLDAS_SNAPSHOT.lower()}\",\n",
    "    icechunk_href=\"s3://nasa-waterinsight/virtual-zarr-store/NLDAS-3-icechunk/\",\n",
    "    snapshot_id=NLDAS_SNAPSHOT,\n",
    "    storage_schemes={\"aws-s3-nasa-waterinsight\": {\n",
    "        \"type\": \"aws-s3\", \"bucket\": \"nasa-waterinsight\",\n",
    "        \"region\": \"us-west-2\", \"anonymous\": True,\n",
    "    }},\n",
    "    title=\"NLDAS-3 Virtual Zarr Store\",\n",
    "    providers=[pystac.Provider(name=\"NLDAS\", roles=[\"producer\",\"processor\",\"licensor\"], url=\"https://ldas.gsfc.nasa.gov/nldas\")],\n",
    "    virtual=True,\n",
    "    virtual_hrefs=[NLDAS_VIRTUAL_SOURCE],\n",
    "    temporal_dimension=\"time\", x_dimension=\"lon\", y_dimension=\"lat\",\n",
    ")\n",
    "\n",
    "print(\"Items built:\")\n",
    "for d in [gfs_item_dict, hrrr_item_dict, nldas_item_dict]:\n",
    "    print(f\"  {d['id']}  bbox={d['bbox']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Assemble the pystac Catalog\n",
    "\n",
    "We use `SELF_CONTAINED` so all links are relative — the catalog can be\n",
    "moved between buckets/prefixes without breaking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = pystac.Catalog(\n",
    "    id=\"weather-forecast-icechunk\",\n",
    "    description=(\n",
    "        \"Public weather forecast datasets stored as Icechunk repositories on AWS S3. \"\n",
    "        \"All items can be opened directly with xarray via xpystac.\"\n",
    "    ),\n",
    "    catalog_type=pystac.CatalogType.SELF_CONTAINED,\n",
    ")\n",
    "\n",
    "for item_dict in [gfs_item_dict, hrrr_item_dict, nldas_item_dict]:\n",
    "    # from_dict preserves top-level extra_fields (e.g. storage:schemes)\n",
    "    catalog.add_item(pystac.Item.from_dict(item_dict))\n",
    "\n",
    "catalog.normalize_hrefs(CATALOG_ROOT)\n",
    "\n",
    "# Verify hrefs look right before writing\n",
    "print(f\"Catalog href: {catalog.get_self_href()}\")\n",
    "for item in catalog.get_items():\n",
    "    print(f\"  item href: {item.get_self_href()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stac_io = FsspecStacIO()\n",
    "catalog.save(stac_io=stac_io)\n",
    "print(f\"\\nCatalog written to {CATALOG_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Browse with STAC Browser\n",
    "\n",
    "The [Radiant Earth hosted STAC Browser](https://radiantearth.github.io/stac-browser/)\n",
    "is a fully client-side app — paste any public STAC catalog URL and it\n",
    "renders it in the browser with no backend required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_url = f\"{CATALOG_ROOT_HTTPS}/catalog.json\"\n",
    "browser_url = f\"https://radiantearth.github.io/stac-browser/#/external/{catalog_url}\"\n",
    "\n",
    "print(\"Catalog URL:\")\n",
    "print(f\"  {catalog_url}\")\n",
    "print()\n",
    "print(\"STAC Browser URL:\")\n",
    "print(f\"  {browser_url}\")\n",
    "\n",
    "# Clickable link in Jupyter\n",
    "from IPython.display import display, Markdown\n",
    "display(Markdown(f\"[Open in STAC Browser]({browser_url})\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Verify round-trip from catalog\n",
    "\n",
    "Reload the catalog from S3 and confirm items can be opened with xpystac."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xpystac  # noqa: F401 — registers xarray backend\n",
    "\n",
    "loaded_catalog = pystac.Catalog.from_file(\n",
    "    catalog_url, stac_io=FsspecStacIO()\n",
    ")\n",
    "\n",
    "for item in loaded_catalog.get_items():\n",
    "    asset_key = next(k for k in item.assets if \"@\" in k)\n",
    "    asset = item.assets[asset_key]\n",
    "    ds = xr.open_dataset(asset)\n",
    "    print(f\"{item.id}\")\n",
    "    print(f\"  dims:  {dict(ds.sizes)}\")\n",
    "    print(f\"  bbox:  {item.bbox}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
