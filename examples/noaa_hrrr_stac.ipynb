{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a STAC Item for the NOAA HRRR Forecast (dynamical.org Icechunk)\n",
    "\n",
    "This notebook shows how to use `cloudify.stac` to generate a STAC item for the\n",
    "[NOAA HRRR 48-Hour Forecast](https://dynamical.org/catalog/noaa-hrrr-forecast-48-hour/)\n",
    "dataset published by [dynamical.org](https://dynamical.org) as a public Icechunk store on AWS S3.\n",
    "\n",
    "HRRR differs from GFS in one important way: it uses a **Lambert Conformal Conic\n",
    "projection** with `x`/`y` coordinates in metres, not `latitude`/`longitude`.\n",
    "This means:\n",
    "- `rioxarray` is required to reproject the native bounds to WGS84 for the STAC bbox\n",
    "- `x_dimension=\"x\"`, `y_dimension=\"y\"` must be passed explicitly\n",
    "- `reference_system` should reflect the native CRS (read from `ds.rio.crs`)\n",
    "\n",
    "## Install dependencies\n",
    "```\n",
    "pip install icechunk xarray zarr pystac xstac rioxarray pyproj cloudify\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import icechunk\n",
    "import pystac\n",
    "import rioxarray  # registers .rio accessor; required for CRS-aware bbox\n",
    "import xarray as xr\n",
    "\n",
    "from cloudify.stac import build_stac_item_from_icechunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Open the Icechunk store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = \"dynamical-noaa-hrrr\"\n",
    "PREFIX = \"noaa-hrrr-forecast-48-hour/v0.1.0.icechunk/\"\n",
    "REGION = \"us-west-2\"\n",
    "ICECHUNK_HREF = f\"s3://{BUCKET}/{PREFIX}\"\n",
    "\n",
    "storage = icechunk.s3_storage(\n",
    "    bucket=BUCKET,\n",
    "    prefix=PREFIX,\n",
    "    region=REGION,\n",
    "    anonymous=True,\n",
    ")\n",
    "repo = icechunk.Repository.open(storage)\n",
    "session = repo.readonly_session(\"main\")\n",
    "\n",
    "snapshot_id = session.snapshot_id\n",
    "print(f\"snapshot_id: {snapshot_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_zarr(session.store, chunks=None)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Inspect the CRS\n",
    "\n",
    "HRRR uses a Lambert Conformal Conic projection. `ds.rio.crs` gives us the\n",
    "native CRS; `extract_spatial_extent_rio` will automatically reproject the\n",
    "dataset bounds to WGS84 (EPSG:4326) for the STAC bbox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "crs = ds.rio.crs\nprint(f\"Native CRS: {crs}\")\n\n# HRRR's Lambert Conformal Conic projection has no standard EPSG code,\n# so to_epsg() returns None — fall back to the full WKT string.\nreference_system = crs.to_epsg() or crs.to_wkt()\nprint(f\"reference_system type: {'EPSG int' if isinstance(reference_system, int) else 'WKT string'}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define storage schemes and providers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_schemes = {\n",
    "    \"aws-s3-dynamical-noaa-hrrr\": {\n",
    "        \"type\": \"aws-s3\",\n",
    "        \"platform\": \"https://{bucket}.s3.{region}.amazonaws.com\",\n",
    "        \"bucket\": BUCKET,\n",
    "        \"region\": REGION,\n",
    "        \"anonymous\": True,\n",
    "    }\n",
    "}\n",
    "\n",
    "providers = [\n",
    "    pystac.Provider(\n",
    "        name=\"dynamical.org\",\n",
    "        description=\"Analysis-ready, cloud-optimized weather forecast data\",\n",
    "        roles=[\"producer\", \"processor\", \"host\"],\n",
    "        url=\"https://dynamical.org\",\n",
    "    ),\n",
    "    pystac.Provider(\n",
    "        name=\"NOAA NCEP\",\n",
    "        description=\"National Oceanic and Atmospheric Administration — High-Resolution Rapid Refresh\",\n",
    "        roles=[\"producer\", \"licensor\"],\n",
    "        url=\"https://www.ncep.noaa.gov\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build the STAC item\n",
    "\n",
    "Key arguments for HRRR that differ from a plain lat/lon dataset:\n",
    "\n",
    "| Argument | Value | Reason |\n",
    "|---|---|---|\n",
    "| `x_dimension` | `\"x\"` | Projected easting coordinate in metres |\n",
    "| `y_dimension` | `\"y\"` | Projected northing coordinate in metres |\n",
    "| `temporal_dimension` | `\"init_time\"` | Forecast initialisation time |\n",
    "| `reference_system` | native CRS EPSG | Preserves projection info in the datacube extension |\n",
    "| `virtual` | `False` | Regular Icechunk store (not virtual-chunk references) |\n",
    "\n",
    "`extract_spatial_extent_rio` (called internally) uses\n",
    "`rioxarray.transform_bounds(\"EPSG:4326\")` to reproject the native Lambert\n",
    "Conformal bounds to WGS84, which is required for a valid STAC bbox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_id = f\"noaa-hrrr-forecast-48-hour-{snapshot_id.lower()}\"\n",
    "\n",
    "item = build_stac_item_from_icechunk(\n",
    "    ds,\n",
    "    item_id=item_id,\n",
    "    icechunk_href=ICECHUNK_HREF,\n",
    "    snapshot_id=snapshot_id,\n",
    "    storage_schemes=storage_schemes,\n",
    "    title=\"NOAA HRRR 48-Hour Forecast (dynamical.org)\",\n",
    "    description=ds.attrs.get(\"description\",\n",
    "        \"NOAA High-Resolution Rapid Refresh (HRRR) 48-hour forecast data, \"\n",
    "        \"analysis-ready and cloud-optimized by dynamical.org. \"\n",
    "        \"Continental US coverage at 3 km resolution in Lambert Conformal \"\n",
    "        \"Conic projection, initialized every 6 hours from 2018-07-13 to present.\"\n",
    "    ),\n",
    "    providers=providers,\n",
    "    virtual=False,                    # regular icechunk, not virtual\n",
    "    temporal_dimension=\"init_time\",   # forecast initialisation time\n",
    "    x_dimension=\"x\",                  # projected easting (metres)\n",
    "    y_dimension=\"y\",                  # projected northing (metres)\n",
    "    reference_system=reference_system,\n",
    ")\n",
    "\n",
    "print(json.dumps(item, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Inspect key fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"bbox (WGS84):   \", item[\"bbox\"])\nprint(\"start_datetime: \", item[\"properties\"][\"start_datetime\"])\nprint(\"end_datetime:   \", item[\"properties\"][\"end_datetime\"])\nprint(\"variables:      \", list(item[\"properties\"][\"cube:variables\"].keys()))\nprint()\nprint(\"assets:\")\nfor key, asset in item[\"assets\"].items():\n    print(f\"  {key}: {asset['href']}\")\n    print(f\"    snapshot_id: {asset.get('icechunk:snapshot_id')}\")\n    print(f\"    roles:       {asset['roles']}\")\nprint()\nprint(\"storage:schemes at top level:\", \"storage:schemes\" in item)\nprint(\"storage:schemes in properties (should be False):\",\n      \"storage:schemes\" in item.get(\"properties\", {}))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save and round-trip via xpystac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = f\"{item_id}.json\"\n",
    "with open(out_path, \"w\") as f:\n",
    "    json.dump(item, f, indent=2)\n",
    "print(f\"Written to {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload and open via xpystac  (requires: pip install xpystac)\n",
    "loaded_item = pystac.Item.from_file(out_path)\n",
    "\n",
    "asset_key = next(k for k in loaded_item.assets if \"@\" in k)\n",
    "asset = loaded_item.assets[asset_key]\n",
    "print(f\"Opening asset: {asset_key}\")\n",
    "\n",
    "ds_from_stac = xr.open_dataset(asset)\n",
    "ds_from_stac"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}